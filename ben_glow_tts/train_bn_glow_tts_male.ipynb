{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Install Coqui TTS\n",
    "# ! pip install -U pip\n",
    "# ! pip install TTS==0.8.0\n",
    "\n",
    "#!pip install git+https://github.com/coqui-ai/TTS  # from Github\n",
    "\n",
    "\n",
    "# !ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 16 12:07:11 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:65:00.0 Off |                  Off |\r\n",
      "| 33%   55C    P0    94W / 300W |     47MiB / 49140MiB |    100%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1545      G   /usr/lib/xorg/Xorg                 38MiB |\r\n",
      "|    0   N/A  N/A      1797      G   /usr/bin/gnome-shell                7MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ansary/anaconda3/envs/mobassir/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!nvidia-smi\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# Trainer: Where the ✨️ happens.\n",
    "# TrainingArgs: Defines the set of arguments of the Trainer.\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "# GlowTTSConfig: all model related values for training, validating and testing.\n",
    "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
    "\n",
    "from TTS.tts.models.glow_tts import GlowTTS\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig,BaseAudioConfig,CharactersConfig\n",
    "#from TTS.configs import BaseDatasetConfig,BaseAudioConfig,CharactersConfig#GlowTTSConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.utils.speakers import SpeakerManager\n",
    "\n",
    "from TTS.config import load_config\n",
    "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
    "from TTS.tts.models.glow_tts import GlowTTS\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ansary/Shabab\r\n"
     ]
    }
   ],
   "source": [
    "# # !apt install -y espeak\n",
    "# !apt install -y espeak-ng\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndicTTS_Phase2_Bengali_fem_Speaker1_mono\r\n",
      "IndicTTS_Phase2_Bengali_male_Speaker1_mono\r\n"
     ]
    }
   ],
   "source": [
    "!ls bn_tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# output_path = \"tts_train_dir\"\n",
    "# if not os.path.exists(output_path):\n",
    "#     os.makedirs(output_path)\n",
    "\n",
    "male = True\n",
    "pretrained = True\n",
    "\n",
    "pretrained_path = ''\n",
    "if(pretrained):\n",
    "    pretrained_path = '/home/ansary/Shabab/bn_GlowTTS'\n",
    "if(male):\n",
    "    meta_file = '/home/ansary/Shabab/bn_tts/IndicTTS_Phase2_Bengali_male_Speaker1_mono/mono/metadata_male.txt'\n",
    "    root_path = '/home/ansary/Shabab/bn_tts/IndicTTS_Phase2_Bengali_male_Speaker1_mono/mono'\n",
    "else:\n",
    "    meta_file = '/home/ansary/Shabab/bn_tts/IndicTTS_Phase2_Bengali_fem_Speaker1_mono/mono/metadata_female.txt'\n",
    "    root_path = '/home/ansary/Shabab/bn_tts/IndicTTS_Phase2_Bengali_fem_Speaker1_mono/mono'\n",
    "\n",
    "def formatter(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
    "    \"\"\"Normalizes the LJSpeech meta data file to TTS format\n",
    "    https://keithito.com/LJ-Speech-Dataset/\"\"\"\n",
    "    txt_file = meta_file\n",
    "    items = []\n",
    "    speaker_name = \"ljspeech\"\n",
    "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
    "        for line in ttf:\n",
    "            cols = line.split(\"|\")\n",
    "            wav_file = os.path.join(root_path, \"wav\", cols[0] + \".wav\")\n",
    "            try:\n",
    "                text = cols[1]\n",
    "            except:\n",
    "                print(\"not found\")\n",
    "\n",
    "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
    "    return items\n",
    "\n",
    "\n",
    "dataset_config = BaseDatasetConfig(\n",
    "     meta_file_train=meta_file, path=os.path.join(root_path, \"\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseDatasetConfig(name='', path='/home/ansary/Shabab/bn_tts/IndicTTS_Phase2_Bengali_male_Speaker1_mono/mono/', meta_file_train='/home/ansary/Shabab/bn_tts/IndicTTS_Phase2_Bengali_male_Speaker1_mono/mono/metadata_male.txt', ignored_speakers=None, language='', meta_file_val='', meta_file_attn_mask='')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 6187 files in /home/ansary/Shabab/bn_tts/IndicTTS_Phase2_Bengali_male_Speaker1_mono/mono\n"
     ]
    }
   ],
   "source": [
    "# load training samples\n",
    "train_samples, eval_samples = load_tts_samples(dataset_config,formatter=formatter, eval_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6126 61\n"
     ]
    }
   ],
   "source": [
    "print(len(train_samples),len(eval_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'সকাল সাড়ে নটায় লিলুয়া রেল ওয়ার্কশপে,পরিত্যক্ত পাটের স্তুপে,আগুন লাগে\\n',\n",
       " 'audio_file': '/home/ansary/Shabab/bn_tts/IndicTTS_Phase2_Bengali_male_Speaker1_mono/mono/wav/train_bengalimale_01658.wav',\n",
       " 'speaker_name': 'ljspeech',\n",
       " 'root_path': '/home/ansary/Shabab/bn_tts/IndicTTS_Phase2_Bengali_male_Speaker1_mono/mono/',\n",
       " 'language': ''}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the same path as this script as our training folder.\n",
    "output_path = '/home/ansary/Shabab/'\n",
    "\n",
    "audio_config = BaseAudioConfig(\n",
    "     sample_rate = 22050,\n",
    "    resample =True\n",
    ")\n",
    "\n",
    "if(male):\n",
    "    characters_config = CharactersConfig(\n",
    "    pad = '<PAD>',\n",
    "    eos = '।', #'<EOS>', #'।',\n",
    "    bos = '<BOS>',# None,\n",
    "    blank = '<BLNK>',\n",
    "    phonemes = None,\n",
    "    characters =  \"তট৫ভিঐঋখঊড়ইজমএেঘঙসীঢ়হঞ‘ঈকণ৬ঁৗশঢঠ\\u200c১্২৮দৃঔগও—ছউংবৈঝাযফ\\u200dচরষঅৌৎথড়৪ধ০ুূ৩আঃপয়’নলো\",\n",
    "    punctuations = \"-!,|.? \",\n",
    "    )\n",
    "else:\n",
    "    characters_config = CharactersConfig(\n",
    "    pad = '<PAD>',\n",
    "    eos = '।', #'<EOS>', #'।',\n",
    "    bos = '<BOS>',# None,\n",
    "    blank = '<BLNK>',\n",
    "    phonemes = None,\n",
    "    characters =  \"ইগং়’ুঃন১ঝূও‘ঊোছপফৈ৮ষযৎঢঈকঠিজ০৬ীটডএঅঋধচে২৩ণউয়ঢ়খলভৗসহ্ড়দথবঔাঞশরৌম—ঐআৃঘঙ\\u200cঁ৪৫ত\",\n",
    "    punctuations = \".?-!|, \",\n",
    "    )\n",
    "\n",
    "\n",
    "# GlowTTSConfig: all model related values for training, validating and testing.\n",
    "\n",
    "config = GlowTTSConfig(\n",
    "    #use_speaker_embedding = True,\n",
    "    batch_size=400,\n",
    "    eval_batch_size=64,\n",
    "    num_loader_workers=16,\n",
    "    num_eval_loader_workers=16,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=2000,\n",
    "    text_cleaner=\"collapse_whitespace\",\n",
    "    use_phonemes=False,\n",
    "#     phoneme_language=\"bn\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    print_step=50,\n",
    "    print_eval=False,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    "    audio = audio_config,\n",
    "    characters = characters_config,\n",
    "    save_step=1000,\n",
    "    cudnn_benchmark=True,\n",
    "    test_sentences = [\n",
    "        \"পিপলস ইন্স্যুরেন্স অব চায়না ছেষট্টি বছর আগে ব্যবসা চালু করে।\",\n",
    "        \"সোনার বাংলা আমি তোমায় ভালবাসি।\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:True\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ap = AudioProcessor.init_from_config(config)\n",
    "ap.resample = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GlowTTS(\n",
       "  (encoder): Encoder(\n",
       "    (emb): Embedding(87, 192)\n",
       "    (prenet): ResidualConv1dLayerNormBlock(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Conv1d(192, 192, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (1): Conv1d(192, 192, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "        (2): Conv1d(192, 192, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "      )\n",
       "      (norm_layers): ModuleList(\n",
       "        (0): LayerNorm()\n",
       "        (1): LayerNorm()\n",
       "        (2): LayerNorm()\n",
       "      )\n",
       "      (proj): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (encoder): RelativePositionTransformer(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (attn_layers): ModuleList(\n",
       "        (0): RelativePositionMultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): RelativePositionMultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): RelativePositionMultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): RelativePositionMultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): RelativePositionMultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): RelativePositionMultiHeadAttention(\n",
       "          (conv_q): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_k): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_v): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (conv_o): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_1): ModuleList(\n",
       "        (0): LayerNorm()\n",
       "        (1): LayerNorm()\n",
       "        (2): LayerNorm()\n",
       "        (3): LayerNorm()\n",
       "        (4): LayerNorm()\n",
       "        (5): LayerNorm()\n",
       "      )\n",
       "      (ffn_layers): ModuleList(\n",
       "        (0): FeedForwardNetwork(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): FeedForwardNetwork(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): FeedForwardNetwork(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): FeedForwardNetwork(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): FeedForwardNetwork(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): FeedForwardNetwork(\n",
       "          (conv_1): Conv1d(192, 768, kernel_size=(3,), stride=(1,))\n",
       "          (conv_2): Conv1d(768, 192, kernel_size=(3,), stride=(1,))\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layers_2): ModuleList(\n",
       "        (0): LayerNorm()\n",
       "        (1): LayerNorm()\n",
       "        (2): LayerNorm()\n",
       "        (3): LayerNorm()\n",
       "        (4): LayerNorm()\n",
       "        (5): LayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (proj_m): Conv1d(192, 80, kernel_size=(1,), stride=(1,))\n",
       "    (duration_predictor): DurationPredictor(\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (conv_1): Conv1d(192, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm_1): LayerNorm()\n",
       "      (conv_2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (norm_2): LayerNorm()\n",
       "      (proj): Conv1d(256, 1, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (flows): ModuleList(\n",
       "      (0): ActNorm()\n",
       "      (1): InvConvNear()\n",
       "      (2): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): ActNorm()\n",
       "      (4): InvConvNear()\n",
       "      (5): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): ActNorm()\n",
       "      (7): InvConvNear()\n",
       "      (8): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): ActNorm()\n",
       "      (10): InvConvNear()\n",
       "      (11): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): ActNorm()\n",
       "      (13): InvConvNear()\n",
       "      (14): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): ActNorm()\n",
       "      (16): InvConvNear()\n",
       "      (17): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): ActNorm()\n",
       "      (19): InvConvNear()\n",
       "      (20): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): ActNorm()\n",
       "      (22): InvConvNear()\n",
       "      (23): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (24): ActNorm()\n",
       "      (25): InvConvNear()\n",
       "      (26): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (27): ActNorm()\n",
       "      (28): InvConvNear()\n",
       "      (29): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (30): ActNorm()\n",
       "      (31): InvConvNear()\n",
       "      (32): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (33): ActNorm()\n",
       "      (34): InvConvNear()\n",
       "      (35): CouplingBlock(\n",
       "        (start): Conv1d(80, 192, kernel_size=(1,), stride=(1,))\n",
       "        (end): Conv1d(192, 160, kernel_size=(1,), stride=(1,))\n",
       "        (wn): WN(\n",
       "          (in_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "            (3): Conv1d(192, 384, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "          )\n",
       "          (res_skip_layers): ModuleList(\n",
       "            (0): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (1): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (2): Conv1d(192, 384, kernel_size=(1,), stride=(1,))\n",
       "            (3): Conv1d(192, 192, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain = True\n",
    "# continue_path = '/home/apsisdev/mobassir/data/tts/run-September-30-2022_10+55AM-0000000/'\n",
    "# if(retrain):\n",
    "#     config = load_config(os.path.join(continue_path, \"config.json\"))\n",
    "#     print(config)\n",
    "#     checkpoint = torch.load(os.path.join(continue_path, \"best_model.pth\")) #938\n",
    "#     model.load_state_dict(checkpoint[\"model\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.batch_size = 192\n",
    "# config.eval_batch_size = 128\n",
    "# config.num_loader_workers = 16\n",
    "# config.num_eval_loader_workers = 16\n",
    "# config.epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n",
      " > Training Environment:\n",
      " | > Current device: 0\n",
      " | > Num. of GPUs: 1\n",
      " | > Num. of CPUs: 24\n",
      " | > Num. of Torch Threads: 12\n",
      " | > Torch seed: 5431\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " > Restoring from checkpoint_38000.pth ...\n",
      " > Restoring Model...\n",
      " > Restoring Optimizer...\n",
      " > Restoring Scaler...\n",
      " > Model restored from step 38000\n",
      "\n",
      " > Model has 28601809 parameters\n"
     ]
    }
   ],
   "source": [
    "# use continue_path argument below for retraining model from last saved weight https://github.com/coqui-ai/Trainer/blob/main/trainer/trainer.py#L210\n",
    "\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(continue_path = pretrained_path), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Restoring best loss from best_model_35921.pth ...\n",
      " > Starting with loaded last best loss -0.687639\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/8000\u001b[0m\n",
      " --> /home/ansary/Shabab/bn_GlowTTS\n",
      "\n",
      "\u001b[1m > TRAINING (2022-10-16 12:07:16) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 6126\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 114\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 64.72233104799217\n",
      " | \n",
      " | > Max audio length: 602438.0\n",
      " | > Min audio length: 107671.0\n",
      " | > Avg audio length: 281024.02579170745\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 61\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 92\n",
      " | > Min text length: 40\n",
      " | > Avg text length: 64.52459016393442\n",
      " | \n",
      " | > Max audio length: 373032.0\n",
      " | > Min audio length: 149142.0\n",
      " | > Avg audio length: 274765.0\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time: 12.13066 \u001b[0m(+0.00000)\n",
      "     | > avg_loss: -0.54667 \u001b[0m(+0.00000)\n",
      "     | > avg_log_mle: -0.73158 \u001b[0m(+0.00000)\n",
      "     | > avg_loss_dur: 0.18491 \u001b[0m(+0.00000)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 1/8000\u001b[0m\n",
      " --> /home/ansary/Shabab/bn_GlowTTS\n",
      "\n",
      "\u001b[1m > TRAINING (2022-10-16 12:12:43) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 6126\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 114\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 64.72233104799217\n",
      " | \n",
      " | > Max audio length: 602438.0\n",
      " | > Min audio length: 107671.0\n",
      " | > Avg audio length: 281024.02579170745\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 61\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 92\n",
      " | > Min text length: 40\n",
      " | > Avg text length: 64.52459016393442\n",
      " | \n",
      " | > Max audio length: 373032.0\n",
      " | > Min audio length: 149142.0\n",
      " | > Avg audio length: 274765.0\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 11.85803 \u001b[0m(-0.27263)\n",
      "     | > avg_loss:\u001b[91m -0.53403 \u001b[0m(+0.01263)\n",
      "     | > avg_log_mle:\u001b[91m -0.71411 \u001b[0m(+0.01748)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18007 \u001b[0m(-0.00484)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 2/8000\u001b[0m\n",
      " --> /home/ansary/Shabab/bn_GlowTTS\n",
      "\n",
      "\u001b[1m > TRAINING (2022-10-16 12:18:08) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 6126\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 114\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 64.72233104799217\n",
      " | \n",
      " | > Max audio length: 602438.0\n",
      " | > Min audio length: 107671.0\n",
      " | > Avg audio length: 281024.02579170745\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 61\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 92\n",
      " | > Min text length: 40\n",
      " | > Avg text length: 64.52459016393442\n",
      " | \n",
      " | > Max audio length: 373032.0\n",
      " | > Min audio length: 149142.0\n",
      " | > Avg audio length: 274765.0\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 11.83450 \u001b[0m(-0.02354)\n",
      "     | > avg_loss:\u001b[92m -0.54054 \u001b[0m(-0.00651)\n",
      "     | > avg_log_mle:\u001b[92m -0.72453 \u001b[0m(-0.01042)\n",
      "     | > avg_loss_dur:\u001b[91m 0.18399 \u001b[0m(+0.00391)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 3/8000\u001b[0m\n",
      " --> /home/ansary/Shabab/bn_GlowTTS\n",
      "\n",
      "\u001b[1m > TRAINING (2022-10-16 12:23:30) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 6126\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 114\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 64.72233104799217\n",
      " | \n",
      " | > Max audio length: 602438.0\n",
      " | > Min audio length: 107671.0\n",
      " | > Avg audio length: 281024.02579170745\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 61\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 92\n",
      " | > Min text length: 40\n",
      " | > Avg text length: 64.52459016393442\n",
      " | \n",
      " | > Max audio length: 373032.0\n",
      " | > Min audio length: 149142.0\n",
      " | > Avg audio length: 274765.0\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 11.93912 \u001b[0m(+0.10463)\n",
      "     | > avg_loss:\u001b[91m -0.53969 \u001b[0m(+0.00085)\n",
      "     | > avg_log_mle:\u001b[92m -0.72564 \u001b[0m(-0.00111)\n",
      "     | > avg_loss_dur:\u001b[91m 0.18595 \u001b[0m(+0.00196)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 4/8000\u001b[0m\n",
      " --> /home/ansary/Shabab/bn_GlowTTS\n",
      "\n",
      "\u001b[1m > TRAINING (2022-10-16 12:28:44) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 6126\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 114\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 64.72233104799217\n",
      " | \n",
      " | > Max audio length: 602438.0\n",
      " | > Min audio length: 107671.0\n",
      " | > Avg audio length: 281024.02579170745\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 61\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 92\n",
      " | > Min text length: 40\n",
      " | > Avg text length: 64.52459016393442\n",
      " | \n",
      " | > Max audio length: 373032.0\n",
      " | > Min audio length: 149142.0\n",
      " | > Avg audio length: 274765.0\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 11.76128 \u001b[0m(-0.17785)\n",
      "     | > avg_loss:\u001b[92m -0.56307 \u001b[0m(-0.02338)\n",
      "     | > avg_log_mle:\u001b[92m -0.74629 \u001b[0m(-0.02065)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18322 \u001b[0m(-0.00273)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 5/8000\u001b[0m\n",
      " --> /home/ansary/Shabab/bn_GlowTTS\n",
      "\n",
      "\u001b[1m > TRAINING (2022-10-16 12:33:44) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 6126\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 114\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 64.72233104799217\n",
      " | \n",
      " | > Max audio length: 602438.0\n",
      " | > Min audio length: 107671.0\n",
      " | > Avg audio length: 281024.02579170745\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 61\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 92\n",
      " | > Min text length: 40\n",
      " | > Avg text length: 64.52459016393442\n",
      " | \n",
      " | > Max audio length: 373032.0\n",
      " | > Min audio length: 149142.0\n",
      " | > Avg audio length: 274765.0\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 11.96134 \u001b[0m(+0.20006)\n",
      "     | > avg_loss:\u001b[92m -0.56694 \u001b[0m(-0.00387)\n",
      "     | > avg_log_mle:\u001b[92m -0.74993 \u001b[0m(-0.00364)\n",
      "     | > avg_loss_dur:\u001b[92m 0.18299 \u001b[0m(-0.00023)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 6/8000\u001b[0m\n",
      " --> /home/ansary/Shabab/bn_GlowTTS\n",
      "\n",
      "\u001b[1m > TRAINING (2022-10-16 12:39:10) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 6126\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 114\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 64.72233104799217\n",
      " | \n",
      " | > Max audio length: 602438.0\n",
      " | > Min audio length: 107671.0\n",
      " | > Avg audio length: 281024.02579170745\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m   --> STEP: 3/16 -- GLOBAL_STEP: 38100\u001b[0m\n",
      "     | > loss: -0.70847  (-0.70772)\n",
      "     | > log_mle: -0.78478  (-0.78338)\n",
      "     | > loss_dur: 0.07630  (0.07566)\n",
      "     | > amp_scaler: 4096.00000  (4096.00000)\n",
      "     | > grad_norm: 72.99988  (74.35139)\n",
      "     | > current_lr: 0.00029 \n",
      "     | > step_time: 1.35820  (1.32071)\n",
      "     | > loader_time: 24.37860  (13.21199)\n",
      "\n",
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 61\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 92\n",
      " | > Min text length: 40\n",
      " | > Avg text length: 64.52459016393442\n",
      " | \n",
      " | > Max audio length: 373032.0\n",
      " | > Min audio length: 149142.0\n",
      " | > Avg audio length: 274765.0\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 12.02214 \u001b[0m(+0.06080)\n",
      "     | > avg_loss:\u001b[91m -0.56477 \u001b[0m(+0.00217)\n",
      "     | > avg_log_mle:\u001b[91m -0.74368 \u001b[0m(+0.00625)\n",
      "     | > avg_loss_dur:\u001b[92m 0.17891 \u001b[0m(-0.00408)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 7/8000\u001b[0m\n",
      " --> /home/ansary/Shabab/bn_GlowTTS\n",
      "\n",
      "\u001b[1m > TRAINING (2022-10-16 12:44:26) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 6126\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 114\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 64.72233104799217\n",
      " | \n",
      " | > Max audio length: 602438.0\n",
      " | > Min audio length: 107671.0\n",
      " | > Avg audio length: 281024.02579170745\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 61\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 92\n",
      " | > Min text length: 40\n",
      " | > Avg text length: 64.52459016393442\n",
      " | \n",
      " | > Max audio length: 373032.0\n",
      " | > Min audio length: 149142.0\n",
      " | > Avg audio length: 274765.0\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[92m 11.95646 \u001b[0m(-0.06568)\n",
      "     | > avg_loss:\u001b[92m -0.56726 \u001b[0m(-0.00250)\n",
      "     | > avg_log_mle:\u001b[92m -0.74615 \u001b[0m(-0.00247)\n",
      "     | > avg_loss_dur:\u001b[92m 0.17889 \u001b[0m(-0.00003)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 8/8000\u001b[0m\n",
      " --> /home/ansary/Shabab/bn_GlowTTS\n",
      "\n",
      "\u001b[1m > TRAINING (2022-10-16 12:49:46) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 6126\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 114\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 64.72233104799217\n",
      " | \n",
      " | > Max audio length: 602438.0\n",
      " | > Min audio length: 107671.0\n",
      " | > Avg audio length: 281024.02579170745\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m > EVALUATION \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 61\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 92\n",
      " | > Min text length: 40\n",
      " | > Avg text length: 64.52459016393442\n",
      " | \n",
      " | > Max audio length: 373032.0\n",
      " | > Min audio length: 149142.0\n",
      " | > Avg audio length: 274765.0\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n",
      "warning: audio amplitude out of range, auto clipped.\n",
      " | > Synthesizing test sentences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
      "     | > avg_loader_time:\u001b[91m 12.19177 \u001b[0m(+0.23531)\n",
      "     | > avg_loss:\u001b[91m -0.56309 \u001b[0m(+0.00417)\n",
      "     | > avg_log_mle:\u001b[91m -0.73875 \u001b[0m(+0.00740)\n",
      "     | > avg_loss_dur:\u001b[92m 0.17566 \u001b[0m(-0.00323)\n",
      "\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 9/8000\u001b[0m\n",
      " --> /home/ansary/Shabab/bn_GlowTTS\n",
      "\n",
      "\u001b[1m > TRAINING (2022-10-16 12:55:07) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: False\n",
      "| > Number of instances : 6126\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 114\n",
      " | > Min text length: 16\n",
      " | > Avg text length: 64.72233104799217\n",
      " | \n",
      " | > Max audio length: 602438.0\n",
      " | > Min audio length: 107671.0\n",
      " | > Avg audio length: 281024.02579170745\n",
      " | > Num. instances discarded samples: 0\n",
      " | > Batch group size: 0.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shabab",
   "language": "python",
   "name": "mobassir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
