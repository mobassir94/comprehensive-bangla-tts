{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Install Coqui TTS\n",
    "# ! pip install -U pip\n",
    "# ! pip install TTS==0.8.0\n",
    "# import os\n",
    "# !git clone https://github.com/coqui-ai/TTS\n",
    "# os.chdir('TTS/')\n",
    "\n",
    "# !python3 -m pip install -r requirements.txt\n",
    "# !python3 setup.py develop\n",
    "\n",
    "# !ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import torch\n",
    "# Trainer: Where the ✨️ happens.\n",
    "# TrainingArgs: Defines the set of arguments of the Trainer.\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.tts.configs.vits_config import VitsConfig\n",
    "from TTS.tts.models.vits import Vits, VitsAudioConfig\n",
    "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
    "\n",
    "\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig,BaseAudioConfig,CharactersConfig\n",
    "#from TTS.configs import BaseDatasetConfig,BaseAudioConfig,CharactersConfig#GlowTTSConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.utils.speakers import SpeakerManager\n",
    "\n",
    "from TTS.config import load_config\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !apt install -y espeak\n",
    "# !apt install -y espeak-ng\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls bn_tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TTS\n",
    "TTS.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# output_path = \"tts_train_dir\"\n",
    "# if not os.path.exists(output_path):\n",
    "#     os.makedirs(output_path)\n",
    "\n",
    "male = False\n",
    "pretrained = False\n",
    "\n",
    "pretrained_path = ''\n",
    "if(pretrained):\n",
    "    pretrained_path = '/home/ansary/Shabab/vits_4_nov'\n",
    "if(male):\n",
    "    meta_file = '/home/ansary/Shabab/bn_tts/male/mono/metadata_male.txt'\n",
    "    root_path = '/home/ansary/Shabab/bn_tts/male/mono'\n",
    "else:\n",
    "    meta_file = '/home/ansary/Shabab/bn_tts/female/mono/metadata_female.txt'\n",
    "    root_path = '/home/ansary/Shabab/bn_tts/female/mono'\n",
    "\n",
    "def formatter(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
    "    \"\"\"Normalizes the LJSpeech meta data file to TTS format\n",
    "    https://keithito.com/LJ-Speech-Dataset/\"\"\"\n",
    "    txt_file = meta_file\n",
    "    items = []\n",
    "    speaker_name = \"ljspeech\"\n",
    "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
    "        for line in ttf:\n",
    "            cols = line.split(\"|\")\n",
    "            wav_file = os.path.join(root_path, \"wav\", cols[0] + \".wav\")\n",
    "            try:\n",
    "                text = cols[1]\n",
    "            except:\n",
    "                print(\"not found\")\n",
    "\n",
    "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
    "    return items\n",
    "\n",
    "\n",
    "dataset_config = BaseDatasetConfig(\n",
    "     meta_file_train=meta_file, path=os.path.join(root_path, \"\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training samples\n",
    "train_samples, eval_samples = load_tts_samples(dataset_config,formatter=formatter, eval_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_samples),len(eval_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the same path as this script as our training folder.\n",
    "output_path = '/home/ansary/Shabab/'\n",
    "\n",
    "# audio_config = BaseAudioConfig(\n",
    "#      sample_rate = 22050,\n",
    "#     resample =True\n",
    "# )\n",
    "\n",
    "audio_config = VitsAudioConfig(\n",
    "    sample_rate=22050, win_length=1024, hop_length=256, num_mels=80, mel_fmin=0, mel_fmax=None\n",
    ")\n",
    "\n",
    "\n",
    "if(male):\n",
    "    characters_config = CharactersConfig(\n",
    "    pad = '<PAD>',\n",
    "    eos = '।', #'<EOS>', #'।',\n",
    "    bos = '<BOS>',# None,\n",
    "    blank = '<BLNK>',\n",
    "    phonemes = None,\n",
    "    characters =  \"তট৫ভিঐঋখঊড়ইজমএেঘঙসীঢ়হঞ‘ঈকণ৬ঁৗশঢঠ\\u200c১্২৮দৃঔগও—ছউংবৈঝাযফ\\u200dচরষঅৌৎথড়৪ধ০ুূ৩আঃপয়’নলো\",\n",
    "    punctuations = \"-!,|.? \",\n",
    "    )\n",
    "else:\n",
    "    characters_config = CharactersConfig(\n",
    "    pad = '<PAD>',\n",
    "    eos = '।', #'<EOS>', #'।',\n",
    "    bos = '<BOS>',# None,\n",
    "    blank = '<BLNK>',\n",
    "    phonemes = None,\n",
    "    characters =  \"ইগং়’ুঃন১ঝূও‘ঊোছপফৈ৮ষযৎঢঈকঠিজ০৬ীটডএঅঋধচে২৩ণউয়ঢ়খলভৗসহ্ড়দথবঔাঞশরৌম—ঐআৃঘঙ\\u200cঁ৪৫ত\",\n",
    "    punctuations = \".?-!|, \",\n",
    "    )\n",
    "\n",
    "\n",
    "# VitsConfig: all model related values for training, validating and testing.\n",
    "\n",
    "config = VitsConfig(\n",
    "    audio=audio_config,\n",
    "    run_name=\"vits_4_nov\",\n",
    "    batch_size=104,\n",
    "    eval_batch_size=48,\n",
    "    batch_group_size=0,\n",
    "    num_loader_workers=4,\n",
    "    num_eval_loader_workers=4,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=15000,\n",
    "    text_cleaner=None, #\"collapse_whitespace\"\n",
    "    use_phonemes=False,\n",
    "    compute_input_seq_cache=True,\n",
    "    print_step=50,\n",
    "    print_eval=False,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    "    characters = characters_config,\n",
    "    save_step=1000,\n",
    "    cudnn_benchmark=True,\n",
    "    test_sentences = [\n",
    "        'হয়,হয়ে,ওয়া,হয়েছ,হয়েছে,দিয়ে,যায়,দায়,নিশ্চয়,আয়,ভয়,নয়,আয়াত,নিয়ে,হয়েছে,দিয়েছ,রয়ে,রয়েছ,রয়েছে।',\n",
    "        'দেয়,দেওয়া,বিষয়,হয়,হওয়া,সম্প্রদায়,সময়,হয়েছি,দিয়েছি,হয়,হয়েছিল,বিষয়ে,নয়,কিয়াম,ইয়া,দেয়া,দিয়েছে,আয়াতে,দয়া।', \n",
    "        'ইয়াহুদ,নয়,ব্যয়,ইয়াহুদী,নেওয়া,উভয়ে,যায়,হয়েছিল,প্রয়োজন।'\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ap = AudioProcessor.init_from_config(config)\n",
    "# ap.resample = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Vits(config, ap, tokenizer, speaker_manager=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('/home/ansary/Shabab/vits_20_october/best_model_311129.pth')\n",
    "# model.load_state_dict(checkpoint[\"model\"])\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use continue_path argument below for retraining model from last saved weight https://github.com/coqui-ai/Trainer/blob/main/trainer/trainer.py#L210\n",
    "\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(continue_path = pretrained_path), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shabab",
   "language": "python",
   "name": "mobassir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
