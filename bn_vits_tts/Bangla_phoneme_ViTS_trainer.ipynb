{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import torch\n",
    "# Trainer: Where the ✨️ happens.\n",
    "# TrainingArgs: Defines the set of arguments of the Trainer.\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.tts.configs.vits_config import VitsConfig\n",
    "from TTS.tts.models.vits import Vits, VitsAudioConfig\n",
    "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
    "\n",
    "\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig,BaseAudioConfig,CharactersConfig\n",
    "#from TTS.configs import BaseDatasetConfig,BaseAudioConfig,CharactersConfig#GlowTTSConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.utils.speakers import SpeakerManager\n",
    "\n",
    "from TTS.config import load_config\n",
    "\n",
    "from trainer import Trainer, TrainerArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls bn_tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TTS\n",
    "TTS.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path = \"tts_train_dir\"\n",
    "# if not os.path.exists(output_path):\n",
    "#     os.makedirs(output_path)\n",
    "\n",
    "male = True\n",
    "pretrained = False\n",
    "\n",
    "pretrained_path = ''\n",
    "if(pretrained):\n",
    "    pretrained_path = '/home/ansary/Shabab/vits_10_aug_2023-August-09-2023_11+31PM-0000000'\n",
    "if(male):\n",
    "    meta_file = '/home/ansary/Shabab/bn_tts/male/mono/metadata_male.txt'\n",
    "    root_path = '/home/ansary/Shabab/bn_tts/male/mono'\n",
    "else:\n",
    "    meta_file = '/home/ansary/Shabab/bn_tts/female/mono/metadata_female.txt'\n",
    "    root_path = '/home/ansary/Shabab/bn_tts/female/mono'\n",
    "\n",
    "def formatter(root_path, meta_file, **kwargs):  # pylint: disable=unused-argument\n",
    "    \"\"\"Normalizes the LJSpeech meta data file to TTS format\n",
    "    https://keithito.com/LJ-Speech-Dataset/\"\"\"\n",
    "    txt_file = meta_file\n",
    "    items = []\n",
    "    speaker_name = \"ljspeech\"\n",
    "    with open(txt_file, \"r\", encoding=\"utf-8\") as ttf:\n",
    "        for line in ttf:\n",
    "            cols = line.split(\"|\")\n",
    "            wav_file = os.path.join(root_path, \"wav\", cols[0] + \".wav\")\n",
    "            try:\n",
    "                text = cols[1]\n",
    "            except:\n",
    "                print(\"not found\")\n",
    "\n",
    "            items.append({\"text\": text, \"audio_file\": wav_file, \"speaker_name\": speaker_name, \"root_path\": root_path})\n",
    "    return items\n",
    "\n",
    "\n",
    "dataset_config = BaseDatasetConfig(\n",
    "     meta_file_train=meta_file, path=os.path.join(root_path, \"\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training samples\n",
    "train_samples, eval_samples = load_tts_samples(dataset_config,formatter=formatter, eval_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_samples),len(eval_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the same path as this script as our training folder.\n",
    "output_path = '/home/ansary/Shabab/'\n",
    "\n",
    "# audio_config = BaseAudioConfig(\n",
    "#      sample_rate = 22050,\n",
    "#     resample =True\n",
    "# )\n",
    "\n",
    "audio_config = VitsAudioConfig(\n",
    "    sample_rate=22050, win_length=1024, hop_length=256, num_mels=80, mel_fmin=0, mel_fmax=None\n",
    ")\n",
    "\n",
    "\n",
    "# if(male):\n",
    "#     characters_config = CharactersConfig(\n",
    "#     pad = '<PAD>',\n",
    "#     eos = '।', #'<EOS>', #'।',\n",
    "#     bos = '<BOS>',# None,\n",
    "#     blank = '<BLNK>',\n",
    "#     phonemes = None,\n",
    "# #     characters =  \"তট৫ভিঐঋখঊড়ইজমএেঘঙসীঢ়হঞ‘ঈকণ৬ঁৗশঢঠ\\u200c১্২৮দৃঔগও—ছউংবৈঝাযফ\\u200dচরষঅৌৎথড়৪ধ০ুূ৩আঃপয়’নলো\",\n",
    "#     #characters =  \"তট৫ভিঐঋখঊড়ইজমএেঘঙসীঢ়হঞ‘ঈকণ৬ঁৗশঢঠ\\u200c১্২৮দৃঔগও—ছউংবৈঝাযফ\\u200dচরষঅৌৎথড়৪ধ০ুূ৩আঃপয়’নলোˌamɾʃˈonbŋlitjʰɔdkpeɟːfɡuhrʈæsʒɖwəc\",\n",
    "#     characters =  \"ˌamɾʃˈonbŋlitjʰɔdkpeɟːfɡuhrʈæsʒɖwəc\", #\n",
    "\n",
    "#     punctuations = \"-!,|.? \",\n",
    "#     )\n",
    "# else:\n",
    "#     characters_config = CharactersConfig(\n",
    "#     pad = '<PAD>',\n",
    "#     eos = '।', #'<EOS>', #'।',\n",
    "#     bos = '<BOS>',# None,\n",
    "#     blank = '<BLNK>',\n",
    "#     phonemes = None,\n",
    "#     characters =  \"ইগং়’ুঃন১ঝূও‘ঊোছপফৈ৮ষযৎঢঈকঠিজ০৬ীটডএঅঋধচে২৩ণউয়ঢ়খলভৗসহ্ড়দথবঔাঞশরৌম—ঐআৃঘঙ\\u200cঁ৪৫ত\",\n",
    "#     punctuations = \".?-!|, \",\n",
    "#     )\n",
    "\n",
    "\n",
    "# VitsConfig: all model related values for training, validating and testing.\n",
    "\n",
    "config = VitsConfig(\n",
    "    audio=audio_config,\n",
    "    run_name=\"male_vits_17_aug_2023\",\n",
    "    batch_size=48,\n",
    "    eval_batch_size=32,\n",
    "    batch_group_size=0,\n",
    "    num_loader_workers=8,\n",
    "    num_eval_loader_workers=8,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=5000,\n",
    "#     phonemizer=\"espeak-ng\",# multi_phonemizer\n",
    "    text_cleaner='phoneme_cleaners',#'multilingual_cleaners', #\"collapse_whitespace\" phoneme_cleaners multilingual_cleaners\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"bn\",\n",
    "\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    compute_input_seq_cache=True,\n",
    "    add_blank=True,\n",
    "    use_language_weighted_sampler = True,\n",
    "    print_step=50,\n",
    "    print_eval=False,\n",
    "    mixed_precision=False,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    "#     characters = characters_config,\n",
    "    save_step=1000,\n",
    "    cudnn_benchmark=True,\n",
    "    test_sentences = [\n",
    "        'আমার   সোনার বাংলা, আমি তোমায় ভালোবাসি।',\n",
    "        'চিরদিন   তোমার আকাশ, তোমার বাতাস, আমার প্রাণে বাজায় বাঁশি', \n",
    "        'ও মা,   ফাগুনে তোর আমের বনে ঘ্রাণে পাগল করে,মরি হায়, হায় রে।'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = AudioProcessor.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import which\n",
    "print(which('espeak'))\n",
    "print(which('espeak-ng'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Vits(config, ap, tokenizer, speaker_manager=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use continue_path argument below for retraining model from last saved weight https://github.com/coqui-ai/Trainer/blob/main/trainer/trainer.py#L210\n",
    "\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(continue_path = pretrained_path), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TTS\n",
    "TTS.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  > ˌamɾʃˈonbŋlitjʰɔdkpeɟːfɡuh\n",
    "# > rʈæsʒɖwəc \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shabab",
   "language": "python",
   "name": "mobassir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
